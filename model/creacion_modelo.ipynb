{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Obtención de parámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip -q install -U flaml[automl] shap scikit-plot plotly==5.* kaleido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "c8VDHwQbY6Cm",
        "outputId": "e0cb590d-26ef-4dba-e63c-3c2232d8365f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "fname = next(iter(uploaded))\n",
        "df = pd.read_csv(fname, sep=None) # exoplanetas_unificado.csv\n",
        "print(df.shape)\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DJ2fevUY95b",
        "outputId": "d2c02c4b-32b6-4185-de54-78cb1b417e77"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "if not hasattr(np, \"NaN\"):\n",
        "    np.NaN = np.nan\n",
        "import pandas as pd\n",
        "\n",
        "# 1) Detectar columna objetivo\n",
        "POSSIBLE_TARGETS = [\"label\",\"clase\",\"class\",\"status\",\"disposition\",\"disposicion\",\"koi_disposition\",\"objetivo\",\"target\"]\n",
        "target = next((c for c in POSSIBLE_TARGETS if c in df.columns), \"disposition\")\n",
        "print(\"Target:\", target)\n",
        "\n",
        "# 2) Mapear a 3 clases\n",
        "LABEL_MAP_FP = {\"FALSE POSITIVE\",\"FP\",\"FA\",\"REFUTED\",\"REFUTED PLANET\",\"REFUTED [PLANET]\",\"FALSE POSITIVE [CANDIDATE]\"}\n",
        "LABEL_MAP_CONFIRMED = {\"CONFIRMED\",\"CP\",\"KP\",\"KNOWN PLANET\",\"CONFIRMED [PLANET]\"}\n",
        "LABEL_MAP_CANDIDATE = {\"CANDIDATE\",\"PC\",\"APC\",\"NOT DISPOSITIONED\",\"NOT DISPOSITIONED\"}  # NBSP posible\n",
        "\n",
        "def _norm(s: str) -> str:\n",
        "    s = str(s).replace(\"\\xa0\",\" \")\n",
        "    s = re.sub(r\"\\[[^\\]]*\\]\",\"\", s)\n",
        "    s = re.sub(r\"[^A-Za-z ]+\",\" \", s).upper()\n",
        "    return re.sub(r\"\\s+\",\" \", s).strip()\n",
        "\n",
        "FP = {_norm(x) for x in LABEL_MAP_FP}\n",
        "CF = {_norm(x) for x in LABEL_MAP_CONFIRMED}\n",
        "CD = {_norm(x) for x in LABEL_MAP_CANDIDATE}\n",
        "\n",
        "def canonical_label(s):\n",
        "    if pd.isna(s): return np.nan\n",
        "    t = _norm(s)\n",
        "    if t in FP or \"REFUTED\" in t:           return \"FALSE POSITIVE\"\n",
        "    if t in CF or \"KNOWN PLANET\" in t:      return \"CONFIRMED\"\n",
        "    if t in CD or \"NOT DISPOSITIONED\" in t: return \"CANDIDATE\"\n",
        "    if \"FALSE\" in t and \"POSITIVE\" in t:    return \"FALSE POSITIVE\"\n",
        "    if \"CONFIRM\" in t:                      return \"CONFIRMED\"\n",
        "    if \"CANDIDATE\" in t:                    return \"CANDIDATE\"\n",
        "    return np.nan\n",
        "\n",
        "df[\"target_raw\"] = df[target]\n",
        "df[target] = df[target].apply(canonical_label)\n",
        "df = df[df[target].isin([\"CONFIRMED\",\"CANDIDATE\",\"FALSE POSITIVE\"])].copy()\n",
        "print(df[target].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DyjOL9_ZCsQ",
        "outputId": "53e97b9f-349e-4642-a883-868e51c98914"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "\n",
        "# A) Columnas a excluir SIEMPRE (IDs) como en tu AutoML\n",
        "id_cols = [c for c in df.columns if any(k in c.lower() for k in [\"id\",\"name\",\"pl_name\",\"tic\",\"kepid\",\"kepoi\"])]\n",
        "\n",
        "# B) Columnas con ALTO riesgo de fuga (predicciones, etiquetas o derivados)\n",
        "LEAK_PATTERNS = [\n",
        "    \"prediction\", \"predic\", \"predicho\", \"pred\", \"label\", \"disposition\",\n",
        "    \"disposicion\", \"status\", \"class\", \"target\", \"objetivo\",\n",
        "    \"koi_disposition\", \"result\", \"score\", \"proba\", \"fold\", \"kfold\", \"split\"\n",
        "]\n",
        "LEAK_EXACT = {\"prediction_label\",\"prediction_score\",\"Label\",\"Score\",\"target_raw\"}\n",
        "\n",
        "leak_cols = [c for c in df.columns if c in LEAK_EXACT or any(pat in c.lower() for pat in LEAK_PATTERNS)]\n",
        "\n",
        "# C) Columnas a excluir adicionalmente (RA y DEC)\n",
        "coords_cols = [c for c in df.columns if c.strip().upper() in [\"RA\", \"DEC\"]]\n",
        "\n",
        "# D) Construimos X e y como en el AutoML, pero SIN estas columnas\n",
        "y = df[target].astype(str)\n",
        "X = df.drop(columns=list(set([target] + id_cols + leak_cols + coords_cols)))\n",
        "\n",
        "print(f\"Columnas eliminadas (potencial fuga): {sorted(set(leak_cols + coords_cols + [target]))}\")\n",
        "print(f\"Total features elegidas: {X.shape[1]}\")\n",
        "# (si quieres verlas) print(sorted(X.columns.tolist())[:50])\n",
        "\n",
        "# E) Preprocesado igual que antes: median numérica + OneHot categórica\n",
        "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "preprocess = ColumnTransformer([\n",
        "    (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
        "    (\"cat\", Pipeline([\n",
        "        (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "    ]), cat_cols)\n",
        "])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "from flaml import AutoML\n",
        "automl = AutoML()\n",
        "automl.fit(\n",
        "    X_train=X_train, y_train=y_train,\n",
        "    X_val=X_test,   y_val=y_test,\n",
        "    task=\"classification\",\n",
        "    metric=\"macro_f1\",              # robusto con clases balanceadas/desbalanceadas\n",
        "    estimator_list=[\"lgbm\",\"xgboost\",\"rf\",\"extra_tree\",\"lrl1\"],\n",
        "    time_budget=600,\n",
        "    seed=42,\n",
        "    log_file_name=\"automl.log\"\n",
        ")\n",
        "print(\"Best:\", automl.best_estimator, automl.best_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "preds  = np.array(automl.predict(X_test))\n",
        "probas = automl.predict_proba(X_test)\n",
        "\n",
        "print(classification_report(y_test, preds, digits=3))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5.5,5))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, preds ,cmap=\"Blues\", ax=ax, normalize=None)\n",
        "ax.set_title(\"Confusion Matrix (3 classes)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldB0TbRub8JF"
      },
      "outputs": [],
      "source": [
        "# Force plot por muestra (¿por qué se clasificó así?)\n",
        "i = 0\n",
        "shap.force_plot(getattr(explainer, 'expected_value', [explainer.expected_value])[0],\n",
        "                shap_values[0][i] if isinstance(shap_values, list) else shap_values[i],\n",
        "                matplotlib=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xSKbJlUcC1o"
      },
      "outputs": [],
      "source": [
        "def explain_row(idx, k=8):\n",
        "    x = X_test.iloc[[idx]]\n",
        "    y_true = y_test.iloc[idx]\n",
        "    proba = automl.predict_proba(x)[0]\n",
        "    y_pred = automl.predict(x)[0]\n",
        "    # SHAP local (si está disponible)\n",
        "    try:\n",
        "        x_t = preprocess.transform(x)\n",
        "        sv_all = explainer.shap_values(x_t)\n",
        "        if isinstance(sv_all, list):\n",
        "            class_idx = list(automl.model.classes_).index(y_pred)\n",
        "            sv = sv_all[class_idx][0]\n",
        "        else:\n",
        "            sv = sv_all[0]\n",
        "        names = preprocess.get_feature_names_out()\n",
        "        top = dict(sorted(zip(names, np.abs(sv)), key=lambda t: t[1], reverse=True)[:k])\n",
        "    except Exception as e:\n",
        "        top = {\"info\": f\"No SHAP local por {e}\"}\n",
        "    return {\"y_true\": str(y_true), \"y_pred\": str(y_pred),\n",
        "            \"probas\": dict(zip(automl.model.classes_, proba)),\n",
        "            \"top_features\": top}\n",
        "\n",
        "# Mapeo dataset → fuzzy\n",
        "MAP = {\n",
        "    \"radius\":  \"pl_radio\",\n",
        "    \"teq\":     \"pl_temperatura_eq\",\n",
        "    \"insol\":   \"insolacion\",\n",
        "    \"period\":  \"periodo_orbital\",\n",
        "    \"st_teff\": \"st_temperatura\",\n",
        "    \"st_rad\":  \"st_radio\",\n",
        "    \"st_logg\": \"st_gravedad\",\n",
        "}\n",
        "\n",
        "def to_fuzzy_input(row):\n",
        "    def g(k, default=np.nan):\n",
        "        col = MAP[k]; return float(row.get(col, default))\n",
        "    return {\"radius\": g(\"radius\",1.0),\"teq\":g(\"teq\",290),\"insol\":g(\"insol\",1.0),\n",
        "            \"period\":g(\"period\",50),\"st_teff\":g(\"st_teff\",5777),\n",
        "            \"st_rad\":g(\"st_rad\",1.0),\"st_logg\":g(\"st_logg\",4.4)}\n",
        "\n",
        "from logicaDifusa import definir_variables as fuzzy_ihl\n",
        "\n",
        "def predict_with_fuzzy(idx):\n",
        "    x = X_test.iloc[[idx]]\n",
        "    raw = df.loc[x.index[0]]\n",
        "    y_pred = automl.predict(x)[0]\n",
        "\n",
        "    out = explain_row(idx, k=6)\n",
        "    out[\"fuzzy\"] = None\n",
        "    if y_pred in (\"CONFIRMED\",\"CANDIDATE\"):\n",
        "        fin = to_fuzzy_input(raw)\n",
        "        ihl, cats = fuzzy_ihl(fin)\n",
        "        out[\"fuzzy\"] = {\"ihl_score\": float(ihl), \"ihl_categorias\": cats}\n",
        "    return out\n",
        "\n",
        "predict_with_fuzzy(0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Uso de los parámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# ========= Cargar datos =========\n",
        "df = pd.read_csv(\"exoplanetas_unificado.csv\")\n",
        "\n",
        "# Quitar RA y DEC (correcto)\n",
        "df = df.drop(columns=[\"RA\", \"DEC\"])\n",
        "\n",
        "# ========= Normalizar etiquetas =========\n",
        "LABEL_MAP_FP = {\"FALSE POSITIVE\", \"FP\", \"FA\", \"REFUTED [PLANET]\", \"FALSE POSITIVE [CANDIDATE]\"}\n",
        "LABEL_MAP_CONFIRMED = {\"CONFIRMED\", \"CP\", \"KP\", \"KNOWN PLANET\"}\n",
        "LABEL_MAP_CANDIDATE = {\"CANDIDATE\", \"PC\", \"APC\", \"NOT DISPOSITIONED\"}\n",
        "\n",
        "def normalize_label(label):\n",
        "    if label in LABEL_MAP_FP:\n",
        "        return \"FALSE POSITIVE\"\n",
        "    elif label in LABEL_MAP_CONFIRMED:\n",
        "        return \"CONFIRMED\"\n",
        "    elif label in LABEL_MAP_CANDIDATE:\n",
        "        return \"CANDIDATE\"\n",
        "    else:\n",
        "        return \"OTHER\"\n",
        "\n",
        "# Aplicar normalización\n",
        "y = df[\"label\"].astype(str).apply(normalize_label)\n",
        "\n",
        "# Filtrar solo las clases válidas\n",
        "mask = y != \"OTHER\"\n",
        "df = df[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# ========= Separar X e y =========\n",
        "# Quitamos columnas no numéricas que XGBoost no acepta\n",
        "X = df.drop(columns=[\"label\", \"mission\", \"object_id\"])\n",
        "\n",
        "# ========= Codificar etiquetas =========\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "class_names = le.classes_\n",
        "\n",
        "# ========= Train/test split =========\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "# ========= Modelo =========\n",
        "params = {\n",
        "        'n_estimators': 1080,\n",
        "        'max_leaves': 45,\n",
        "        'min_child_weight': 0.18534714676420808,\n",
        "        'learning_rate': 0.07207682269307049,\n",
        "        'subsample': 0.922847602771779,\n",
        "        'colsample_bylevel': 1.0,\n",
        "        'colsample_bytree': 1.0,\n",
        "        'reg_alpha': 0.0014249188153002787,\n",
        "        'reg_lambda': 0.2021107529299507\n",
        "}\n",
        "\n",
        "model = xgb.XGBClassifier(**params)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ========= Predicciones =========\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_proba = model.predict_proba(X_test)\n",
        "\n",
        "# ========= Matriz de confusión =========\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=sns.color_palette([\"#00ffe5\", \"#ff00ff\", \"#00aa88\"]),\n",
        "    xticklabels=class_names,\n",
        "    yticklabels=class_names,\n",
        "    cbar=False\n",
        ")\n",
        "plt.xlabel(\"Predicción\", fontsize=12)\n",
        "plt.ylabel(\"Verdadero\", fontsize=12)\n",
        "plt.title(\"Matriz de Confusión\", fontsize=14, fontweight=\"bold\")\n",
        "plt.savefig(\"matriz_confusion.png\", dpi=300, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# ========= Curvas ROC multiclase =========\n",
        "y_test_bin = label_binarize(y_test, classes=np.arange(len(class_names)))\n",
        "n_classes = y_test_bin.shape[1]\n",
        "\n",
        "fpr, tpr, roc_auc = {}, {}, {}\n",
        "colors = [\"#00ffe5\", \"#ff00ff\", \"#00aa88\"]\n",
        "\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_pred_proba.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "plt.figure(figsize=(7, 6))\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=2, label=f\"{class_names[i]} (AUC = {roc_auc[i]:.2f})\")\n",
        "\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"], linestyle=\"--\", color=\"black\", label=f\"Micro-average (AUC = {roc_auc['micro']:.2f})\", lw=2)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], \"k--\", lw=1)\n",
        "plt.xlabel(\"Tasa de Falsos Positivos\", fontsize=12)\n",
        "plt.ylabel(\"Tasa de Verdaderos Positivos\", fontsize=12)\n",
        "plt.title(\"Curvas ROC Multiclase\", fontsize=14, fontweight=\"bold\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.savefig(\"curva_ROC_multiclase.png\", dpi=300, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# ========= Reporte de clasificación =========\n",
        "print(\"===== Reporte de Clasificación =====\")\n",
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# ========= Cargar datos =========\n",
        "df = pd.read_csv(\"exoplanetas_unificado.csv\")\n",
        "\n",
        "# Quitar RA y DEC (correcto)\n",
        "df = df.drop(columns=[\"RA\", \"DEC\"])\n",
        "\n",
        "# ========= Normalizar etiquetas =========\n",
        "LABEL_MAP_FP = {\"FALSE POSITIVE\", \"FP\", \"FA\", \"REFUTED [PLANET]\", \"FALSE POSITIVE [CANDIDATE]\"}\n",
        "LABEL_MAP_CONFIRMED = {\"CONFIRMED\", \"CP\", \"KP\", \"KNOWN PLANET\"}\n",
        "LABEL_MAP_CANDIDATE = {\"CANDIDATE\", \"PC\", \"APC\", \"NOT DISPOSITIONED\"}\n",
        "\n",
        "def normalize_label(label):\n",
        "    if label in LABEL_MAP_FP:\n",
        "        return \"FALSE POSITIVE\"\n",
        "    elif label in LABEL_MAP_CONFIRMED or label in LABEL_MAP_CANDIDATE:\n",
        "        return \"PLANET\"   # clase positiva (confirmados + candidatos)\n",
        "    else:\n",
        "        return \"OTHER\"\n",
        "\n",
        "y = df[\"label\"].astype(str).apply(normalize_label)\n",
        "\n",
        "# Filtrar solo las clases válidas\n",
        "mask = y != \"OTHER\"\n",
        "df = df[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# ========= Separar X e y =========\n",
        "X = df.drop(columns=[\"label\", \"mission\", \"object_id\"])\n",
        "\n",
        "# ========= Codificar etiquetas =========\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "class_names = le.classes_   # [\"FALSE POSITIVE\", \"PLANET\"]\n",
        "\n",
        "# ========= Train/test split =========\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "# ========= Modelo binario =========\n",
        "params = {\n",
        "    'n_estimators': 228,\n",
        "    'max_leaves': 143,\n",
        "    'min_child_weight': 0.5296177148580371,\n",
        "    'learning_rate': 0.07186279434453446,\n",
        "    'subsample': 0.9911870640734798,\n",
        "    'colsample_bylevel': 0.8415892418572928,\n",
        "    'colsample_bytree': 1.0,\n",
        "    'reg_alpha': 0.018870980731499835,\n",
        "    'reg_lambda': 0.8602626316154423,\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'logloss'\n",
        "}\n",
        "\n",
        "model = xgb.XGBClassifier(**params)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ========= Guardar modelo y encoder =========\n",
        "joblib.dump({\"model\": model, \"label_encoder\": le}, \"xgb_exoplanet_model.pkl\")\n",
        "print(\"✅ Modelo guardado en xgb_exoplanet_model.pkl\")\n",
        "\n",
        "# ========= Predicciones =========\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# ========= Matriz de confusión =========\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=sns.color_palette([\"#00ffe5\", \"#ff00ff\"]),  # tu paleta\n",
        "    xticklabels=class_names,\n",
        "    yticklabels=class_names,\n",
        "    cbar=False\n",
        ")\n",
        "plt.xlabel(\"Predicción\", fontsize=12)\n",
        "plt.ylabel(\"Verdadero\", fontsize=12)\n",
        "plt.title(\"Matriz de Confusión (Binaria)\", fontsize=14, fontweight=\"bold\")\n",
        "plt.savefig(\"matriz_confusion_binaria.png\", dpi=300, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# ========= Curva ROC =========\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.plot(fpr, tpr, lw=2, color=colors[0], label=f\"PLANET (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], \"k--\", lw=1)\n",
        "plt.xlabel(\"Tasa de Falsos Positivos\", fontsize=12)\n",
        "plt.ylabel(\"Tasa de Verdaderos Positivos\", fontsize=12)\n",
        "plt.title(\"Curva ROC (Binaria)\", fontsize=14, fontweight=\"bold\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.savefig(\"curva_ROC_binaria.png\", dpi=300, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# ========= Reporte de clasificación =========\n",
        "print(\"===== Reporte de Clasificación =====\")\n",
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shap\n",
        "\n",
        "# ========= Calcular valores SHAP =========\n",
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# ========= Gráfico resumen (importancia por variable) =========\n",
        "plt.figure(figsize=(8, 6))\n",
        "shap.summary_plot(\n",
        "    shap_values,\n",
        "    X_test,\n",
        "    plot_type=\"bar\",\n",
        "    color=colors[0],  # tu color principal: \"#00ffe5\"\n",
        "    show=False\n",
        ")\n",
        "plt.title(\"Importancia de las Variables (SHAP)\", fontsize=14, fontweight=\"bold\")\n",
        "plt.xlabel(\"Valor medio |SHAP| (impacto promedio en la predicción)\", fontsize=11)\n",
        "plt.savefig(\"importancia_SHAP_bar.png\", dpi=300, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# ========= Gráfico detallado (beeswarm / dispersión) =========\n",
        "plt.figure(figsize=(10, 6))\n",
        "shap.summary_plot(\n",
        "    shap_values,\n",
        "    X_test,\n",
        "    cmap=plt.cm.colors.ListedColormap([\"#00ffe5\", \"#ff00ff\", \"#00aa88\"]),\n",
        "    show=False\n",
        ")\n",
        "plt.title(\"Contribución de cada Variable (SHAP)\", fontsize=14, fontweight=\"bold\")\n",
        "plt.savefig(\"importancia_SHAP_beeswarm.png\", dpi=300, bbox_inches=\"tight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "import os \n",
        "from google.colab import drive \n",
        "\n",
        "print(os.listdir(\"/content/drive\"))\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "joblib.dump(model, \"/content/drive/MyDrive/xgb_exoplanet_model.pkl\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
